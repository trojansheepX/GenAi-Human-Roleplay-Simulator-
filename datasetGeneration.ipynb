{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c858cdb3",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c85fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumbase import Driver\n",
    "\n",
    "driver = Driver(uc=True, headless = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb7e4f0",
   "metadata": {},
   "source": [
    "# Extraction from Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a410991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logginned the browser with personal ID, and aim is to scrap Human Comments from public posts.\n",
    "from fb_utils import *\n",
    "\n",
    "post_links = []\n",
    "\n",
    "posts = driver.find_element(\n",
    "    'xpath',\n",
    "    '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div/div[2]/div/div/div/div[3]/div/div[3]/div/div[2]') \\\n",
    "                                                                                     .find_elements('tag name', 'div')[13:] # starting 13 are not posts\n",
    "\n",
    "for post in posts:\n",
    "    l = get_link(post)\n",
    "    post_links.append(l)\n",
    "\n",
    "save_to_file(post_links, 'post_links_fb.pkl')\n",
    "\n",
    "facebook_comments = {}\n",
    "for post_link in post_links:\n",
    "    driver.open(post_link)\n",
    "    driver.wait(1)\n",
    "    driver.scroll_to_bottom()\n",
    "    driver.wait(1)\n",
    "    driver.scroll_to_top()\n",
    "    driver.wait(1)\n",
    "\n",
    "    title = driver.find_element('tag name', 'title').text\n",
    "    comments = driver.find_elements('xpath', '//div[@class=\"kvgmc6g5 cxmmr5t8 oygrvhab hcukyx3x c1et5uql\"]')\n",
    "    for comment in comments:\n",
    "        facebook_comments[title] = facebook_comments.get(title, []) + [comment.text] + ['\\n']\n",
    "    \n",
    "save_to_file(facebook_comments, 'facebook_comments.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a9c37",
   "metadata": {},
   "source": [
    "# Extraction from Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = ['r/']\n",
    "\n",
    "post_links = []\n",
    "for community_link in communities:\n",
    "    driver.get(community_link)\n",
    "    par = driver.find_element('xpath', '//*[@id=\"main-content\"]/div[2]/shreddit-feed').find_elements('tag name', 'article')\n",
    "    \n",
    "    l = par.find_element('tag name', 'a').get_attribute('href')\n",
    "    post_links.append(l)\n",
    "\n",
    "save_to_file(post_links, 'post_links_reddit.pkl')\n",
    "\n",
    "reddit_comments = {}\n",
    "for post_link in post_links:\n",
    "    driver.get(post_link)\n",
    "    title = driver.find_element('xpath', '//*[@id=\"post-title-t3_1fdyleo\"]').text\n",
    "    content = driver.find_element('xpath', '//*[@id=\"t3_1fdyleo\"]/div[2]').text\n",
    "    \n",
    "    comments = driver.find_elements('tag name', 'shreddit-comment')\n",
    "    for comment in comments:\n",
    "        t = comment.text\n",
    "        reddit_comments[title] = reddit_comments.get(title, []) + [t] + ['\\n']\n",
    "\n",
    "save_to_file(reddit_comments, 'reddit_comments.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b87d9a2",
   "metadata": {},
   "source": [
    "# Extraction from twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f633b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "from twitter_utils import *\n",
    "\n",
    "# Step 1: Scrape tweet links\n",
    "driver.get(\"https://twitter.com/search?q=public%20tweets&src=typed_query\")\n",
    "\n",
    "post_links = []\n",
    "tweets = scroll_and_collect_tweets(driver)\n",
    "\n",
    "for tweet in tweets:\n",
    "    link = get_tweet_link(tweet)\n",
    "    if link:\n",
    "        post_links.append(link)\n",
    "\n",
    "# Save the tweet links to a file\n",
    "save_to_file(post_links, 'post_links_twitter.pkl')\n",
    "\n",
    "# Step 2: Scrape comments from each tweet\n",
    "twitter_comments = {}\n",
    "\n",
    "for post_link in post_links:\n",
    "    driver.get(post_link)\n",
    "    time.sleep(3)  # Allow time for the page to load\n",
    "    # Get the tweet title/content\n",
    "    try:\n",
    "        title = driver.find_element('xpath', '//div[@data-testid=\"tweetText\"]').text\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting tweet text: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Get all replies (tweets under the main tweet)\n",
    "    try:\n",
    "        replies = driver.find_elements('xpath', '//div[@data-testid=\"reply\"]')\n",
    "        for reply in replies:\n",
    "            reply_text = reply.text\n",
    "            twitter_comments[title] = twitter_comments.get(title, []) + [reply_text] + ['\\n']\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting replies: {e}\")\n",
    "\n",
    "# Save the collected comments to a file\n",
    "save_to_file(twitter_comments, 'twitter_comments.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a1de5",
   "metadata": {},
   "source": [
    "# Combining to create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157eac6-8a2c-4a3a-b9e7-00969067e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "# Load extracted data from Facebook, Reddit, and Twitter\n",
    "facebook_comments = load_data('facebook_comments.pkl')\n",
    "reddit_comments = load_data('reddit_comments.pkl')\n",
    "twitter_comments = load_data('twitter_comments.pkl')\n",
    "\n",
    "# Create the dataset in the required format\n",
    "create_dataset_format(facebook_comments, 'facebook_language_model_dataset.txt')\n",
    "create_dataset_format(reddit_comments, 'reddit_language_model_dataset.txt')\n",
    "create_dataset_format(twitter_comments, 'twitter_language_model_dataset.txt')\n",
    "\n",
    "# Optional: Combine datasets into one file if needed\n",
    "def combine_datasets(output_file, *datasets):\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for dataset in datasets:\n",
    "            with open(dataset, 'r', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "# Combine all datasets into one (optional step)\n",
    "combine_datasets('combined_language_model_dataset.txt',\n",
    "                 'facebook_language_model_dataset.txt',\n",
    "                 'reddit_language_model_dataset.txt',\n",
    "                 'twitter_language_model_dataset.txt')\n",
    "\n",
    "# Load the dataset from the combined file\n",
    "dataset = load_dataset_from_file('combined_language_model_dataset.txt')\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "save_dataset_to_csv(dataset, 'language_model_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10277a34",
   "metadata": {},
   "source": [
    "Dealing with second part of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbaadf9",
   "metadata": {},
   "source": [
    "# Chat Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Datasets import Dataset\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/Deepakchawla/streamlit-example/master/cleaned_dataset_personality.csv')\n",
    "df.head()\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.remove_columns('Unnamed: 0')\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb4f03",
   "metadata": {},
   "source": [
    "# Defining GPT-LLM object using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7bee53-7e20-46f0-991f-6193f5c74253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "import os\n",
    "\n",
    "BASE_URL = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "DEPLOYMENT_NAME= \"gpt4\"\n",
    "API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"] \n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(azure_deployment=DEPLOYMENT_NAME,\n",
    "                      model_name = \"gpt-4\",\n",
    "                      openai_api_version=\"2024-02-01\",\n",
    "                #       temperature=0.7,\n",
    "                      openai_api_key=API_KEY,\n",
    "                      azure_endpoint=BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba68a0",
   "metadata": {},
   "source": [
    "# Setting the prompt for the Enhancing the dataset using GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"\"\"This is the basic personality setting of user 2:\n",
    "\n",
    "        {user2_personality}\n",
    "\n",
    "\n",
    "        This is the conversation between user 1 and user 2:\n",
    "        \n",
    "        {conversation}\n",
    "\n",
    "\n",
    "        After analyzing the above information your task is to give a detailed personality of user2, along with some examples of what he would do in various situations you have inferred from his personality.\n",
    "        Use a suitable random name for user 2 in your answer, and replace that name with every occurrence of user 2, \n",
    "        You can create fictional data about the personality of user 2 which does not conflict with the provided conversation.\n",
    "        You are supposed to give the answer in a format such that you are explaining the personality of user 2 to me. You can NOT include user 1 in user 2's personality traits.\n",
    "        Just include the facts, the habits and how the user 2 would behave in different situations. Make them very descriptive.\n",
    "        Add any missing  or additional fictional details which make the final answer even better and revealing about user 2.\n",
    "\n",
    "        You are only supposed to give the character sketch of user 2 in your answer with the chosen name, do not mention user1 or user2 in the answer. Don't give any other information as the output. your output should be directly usable as a character sketch of the person without any additional details provided. You are giving a model answer and not talking with the user, you just have to give the answer without conversing. Where you directly start with the character sketch with only facts about user 2, without ever mentioning the gfact that user 2's name has been changed.\n",
    "        You are telling me the personality of user 2 in a very formal manner where we dont do uneccessary talking and only talk about facts. You just directly give the facts to me without any pleasentries. For example you just start with Alex is a this... or you start with Mary is like this...\n",
    "        \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt, input_variables=[\"user2_personality\", \"conversation\"] )\n",
    "\n",
    "llm_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97267871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "def infer(example):\n",
    "    try:\n",
    "        example['personality'] = llm_chain.invoke({'user2_personality': example['user 2 personas'], 'conversation': example['Best Generated Conversation']}).content\n",
    "    except:\n",
    "        example['personality'] = None\n",
    "    return example\n",
    "\n",
    "super_results = []\n",
    "with open(r\"C:\\Users\\chait\\Downloads\\super_res\\sup_res.pkl\", 'rb') as f:\n",
    "    super_results = pickle.load(f)\n",
    "\n",
    "BATCH_SIZE = 80\n",
    "for i in range(0,len(ds),BATCH_SIZE):\n",
    "    temp_ds = ds.select(list(range(i, i+BATCH_SIZE))).to_list()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=BATCH_SIZE) as executor:\n",
    "        results = list(tqdm(executor.map(infer, temp_ds), total=len(temp_ds), desc=f\"Processing batch {i}\"))\n",
    "        \n",
    "    super_results.extend(results)\n",
    "    \n",
    "    save_dir = r'C:\\Users\\chait\\Downloads\\super_res'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with open(save_dir+'\\sup_res.pkl', 'wb') as file:\n",
    "        pickle.dump(super_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convo(example):\n",
    "    import random\n",
    "    from langchain.chat_models import AzureChatOpenAI\n",
    "    from langchain import PromptTemplate\n",
    "    from datasets import load_dataset, Dataset\n",
    "    import re\n",
    "    \n",
    "    names = [\n",
    "        \"James\", \"Michael\", \"Robert\", \"John\", \"David\", \"William\", \"Richard\", \"Joseph\", \"Thomas\", \"Christopher\",\n",
    "        \"Charles\", \"Daniel\", \"Matthew\", \"Anthony\", \"Mark\", \"Donald\", \"Steven\", \"Andrew\", \"Paul\", \"Joshua\",\n",
    "        \"Kenneth\", \"Kevin\", \"Brian\", \"Timothy\", \"Ronald\", \"George\", \"Jason\", \"Edward\", \"Jeffrey\", \"Ryan\",\n",
    "        \"Jacob\", \"Nicholas\", \"Gary\", \"Eric\", \"Jonathan\", \"Stephen\", \"Larry\", \"Justin\", \"Scott\", \"Brandon\",\n",
    "        \"Benjamin\", \"Samuel\", \"Gregory\", \"Alexander\", \"Patrick\", \"Frank\", \"Raymond\", \"Jack\", \"Dennis\", \"Jerry\",\n",
    "        \"Tyler\", \"Aaron\", \"Jose\", \"Adam\", \"Nathan\", \"Henry\", \"Zachary\", \"Douglas\", \"Peter\", \"Kyle\", \"Noah\",\n",
    "        \"Ethan\", \"Jeremy\", \"Christian\", \"Walter\", \"Keith\", \"Austin\", \"Roger\", \"Terry\", \"Sean\", \"Gerald\",\n",
    "        \"Carl\", \"Dylan\", \"Harold\", \"Jordan\", \"Jesse\", \"Bryan\", \"Lawrence\", \"Arthur\", \"Gabriel\", \"Bruce\",\n",
    "        \"Logan\", \"Billy\", \"Joe\", \"Alan\", \"Juan\", \"Elijah\", \"Willie\", \"Albert\", \"Wayne\", \"Randy\", \"Mason\",\n",
    "        \"Vincent\", \"Liam\", \"Roy\", \"Bobby\", \"Caleb\", \"Bradley\", \"Russell\", \"Lucas\",\n",
    "        \"Mary\", \"Patricia\", \"Jennifer\", \"Linda\", \"Elizabeth\", \"Barbara\", \"Susan\", \"Jessica\", \"Karen\", \"Sarah\",\n",
    "        \"Lisa\", \"Nancy\", \"Sandra\", \"Betty\", \"Ashley\", \"Emily\", \"Kimberly\", \"Margaret\", \"Donna\", \"Michelle\",\n",
    "        \"Carol\", \"Amanda\", \"Melissa\", \"Deborah\", \"Stephanie\", \"Rebecca\", \"Sharon\", \"Laura\", \"Cynthia\", \"Dorothy\",\n",
    "        \"Amy\", \"Kathleen\", \"Angela\", \"Shirley\", \"Emma\", \"Brenda\", \"Pamela\", \"Nicole\", \"Anna\", \"Samantha\",\n",
    "        \"Katherine\", \"Christine\", \"Debra\", \"Rachel\", \"Carolyn\", \"Janet\", \"Maria\", \"Olivia\", \"Heather\", \"Helen\",\n",
    "        \"Catherine\", \"Diane\", \"Julie\", \"Victoria\", \"Joyce\", \"Lauren\", \"Kelly\", \"Christina\", \"Ruth\", \"Joan\",\n",
    "        \"Virginia\", \"Judith\", \"Evelyn\", \"Hannah\", \"Andrea\", \"Megan\", \"Cheryl\", \"Jacqueline\", \"Madison\", \"Teresa\",\n",
    "        \"Abigail\", \"Sophia\", \"Martha\", \"Sara\", \"Gloria\", \"Janice\", \"Kathryn\", \"Ann\", \"Isabella\", \"Judy\",\n",
    "        \"Charlotte\", \"Julia\", \"Grace\", \"Amber\", \"Alice\", \"Jean\", \"Denise\", \"Frances\", \"Danielle\", \"Marilyn\",\n",
    "        \"Natalie\", \"Beverly\", \"Diana\", \"Brittany\", \"Theresa\", \"Kayla\", \"Alexis\", \"Doris\", \"Lori\", \"Tiffany\"\n",
    "    ]\n",
    "    prompt = \"\"\"Here is the character sketch \n",
    "\n",
    "    {sketch}\n",
    "\n",
    "    Tell me the name of the character whom we are talking about. just tell me the name and nothing else for example if the name is Jack you just say Jack. if the name is Mary Smith you just say Mary, just return the fist name of the character.\"\"\"\n",
    "    prompt = PromptTemplate(template=prompt, input_variables=['sketch'] )\n",
    "    llm_chain = prompt | llm\n",
    "    \n",
    "    \n",
    "    t = example['Best Generated Conversation']\n",
    "    user1_name = random.choice(names)\n",
    "    user2_name = llm_chain.invoke({'sketch' : example['personality']}).content\n",
    "    \n",
    "    def replace_user_names(match):\n",
    "        if \"1\" in match.group(0):\n",
    "            return user1_name\n",
    "        elif \"2\" in match.group(0):\n",
    "            return user2_name\n",
    "        return match.group(0)\n",
    "\n",
    "    t = re.sub(r\"\\[.*?\\]|\\(.*?\\)\\{.*?\\}\", replace_user_names, t)\n",
    "    t = t.split(\" User 1: \")\n",
    "    t[0] = t[0].replace('User 1: ', '')\n",
    "    # display(t)\n",
    "    for i in range(len(t)):\n",
    "        x = t[i].split(' User 2: ')\n",
    "        # display(x)\n",
    "        if len(x)==1:\n",
    "            t = t[:-1]\n",
    "            break\n",
    "        t[i] = {\"user\" : x[0], \"response\" : x[1]}\n",
    "    example['conversation'] = t\n",
    "    example['names'] = {'user1': user1_name, 'user2': user2_name}\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(convo, num_proc = 50)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datasets import Dataset\n",
    "with open(r\"C:\\Users\\chait\\Downloads\\dataset.pkl\", 'rb') as f:\n",
    "    ds = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(ds)\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe69e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers.json import JsonOutputParser\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "def names(row):\n",
    "    prompt = \"\"\"I need to extract the names of 'user 1' and 'user 2' from the text, which are enclosed within triple curly brackets like this\n",
    "    '''{value_1}'''. The format should be a JSON object with two key-value pairs. \n",
    "    user1: user 1 name and user2 : user 2 name. \n",
    "\n",
    "    please output the information in structured JSON format without using markdown code blocks.\"\"\"\n",
    "    prompt = PromptTemplate(template=prompt, input_variables=[\"value_1\"] )\n",
    "    parser = JsonOutputParser()\n",
    "    llm_chain = prompt | llm\n",
    "    t = llm_chain.invoke({'value_1': str(row['conversation'])}).content\n",
    "    t = re.search(r'\\{(.*)\\}', t, re.DOTALL).group(1)\n",
    "    t = parser.invoke(t)\n",
    "    return t\n",
    "\n",
    "df['names'] = df.progress_apply(names, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cad594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat Template\n",
    "# <|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{system_prompt}<|eot_id|>\n",
    "# <|start_header_id|>user<|end_header_id|>\\n\\n{user_message}<|eot_id|>\n",
    "# <|start_header_id|>assistant<|end_header_id|>\\n\\n{assistant_message}<|eot_id|>\n",
    "\n",
    "system_prompt = \"You are {user2_name}. Your role is to engage in conversation with {user1_name}, embodying the personality traits outlined in:\\n\\n{personality}\\n\\nRespond to {user1_name} according to these characteristics as the conversation unfolds.\"\n",
    "\n",
    "\n",
    "def complete(example):\n",
    "    bos_token = \"<|begin_of_text|>\"\n",
    "    start_header = \"<|start_header_id|>\"\n",
    "    end_header = \"<|end_header_id|>\"\n",
    "    eos_token = \"<|eot_id|>\"\n",
    "    t = bos_token + start_header + 'system' + end_header + '\\n\\n' + system_prompt.format(user2_name=example['names']['user2'], user1_name=example['names']['user1'], personality=example['personality'])+eos_token\n",
    "    for ex in example['conversation']:\n",
    "        ex = list(ex.values())\n",
    "        t += start_header + \"user\" + end_header + '\\n\\n' + ex[0] + eos_token\n",
    "        t += start_header + \"assistant\" + end_header + '\\n\\n' + ex[1] + eos_token\n",
    "    return {'text': t}\n",
    "\n",
    "final_ds = dataset.map(complete)\n",
    "final_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds.save_to_disk('dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
